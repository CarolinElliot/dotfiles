{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolinElliot/dotfiles/blob/master/mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-VFhLaVjM-I"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdPlqQngjM-K"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset\n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*?\n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkIDdQ8AjM-L"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits?\n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYU9bsqPjM-L"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMIeOIbxjM-M"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PGNYheInjM-M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z924V9rljM-O"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP-CMc80jM-O"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOiRVHTAjM-P",
        "outputId": "80529570-3524-4bb7-8cd5-098ffe59451b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koy_YBmDjM-P"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziAin64-jM-P"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "UD9BXDmrjM-Q",
        "outputId": "e89535f0-0402-4d7d-b328-4a2d8565ab68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Plot first 9 images from training set\n",
        "plt.figure(figsize=(6,6))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(x_train[i], cmap=\"gray\")   # <-- grayscale\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_77NWubZjM-Q"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSzWlwn6jM-Q"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255.\n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ySC1XegjM-Q"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.**\n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzxqDTGyjM-Q",
        "outputId": "218cf54a-d001-4696-85cf-bb75c5efd65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28)\n",
            "Testing data shape: (10000, 28, 28)\n",
            "Pixel value range after normalization: 0.0 to 1.0\n"
          ]
        }
      ],
      "source": [
        "# Normalize the images: scale values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)\n",
        "print(\"Pixel value range after normalization:\", x_train.min(), \"to\", x_train.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3b-550PjM-R"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sAxTrMEjM-R",
        "outputId": "33d94e81-0436-4aa2-a61d-7851d6a75612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxcoyCkwrONx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tMmhCSJjM-R"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPe09F8hjM-R"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyRze4HzjM-R"
      },
      "outputs": [],
      "source": [
        "from keras.ops import expand_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckd6qJVDjM-R",
        "outputId": "d9977df1-b9c6-4816-bafa-ad5c52f2b93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28, 1, 1)\n",
            "Testing data shape: (10000, 28, 28, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "# Expand dimensions to add channel = 1\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7TJU_IIjM-S"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2albP9xjM-S"
      },
      "source": [
        "One more thing to do for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì\n",
        "\n",
        "* Use **`to_categorical`** to transform your labels.\n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUQMo1t4jM-S",
        "outputId": "757d0760-2732-45a6-a8d6-c49a4ce0cfbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label example: 5\n",
            "One-hot encoded example: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "y_train_cat shape: (60000, 10)\n",
            "y_test_cat shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(\"Original label example:\", y_train[0])\n",
        "print(\"One-hot encoded example:\", y_train_cat[0])\n",
        "print(\"y_train_cat shape:\", y_train_cat.shape)\n",
        "print(\"y_test_cat shape:\", y_test_cat.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "notes: ##one-hot encoding = turning categorical labels into a format the network can learn from."
      ],
      "metadata": {
        "id": "KkPIPcz7svgf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ec-r7ZEHsTSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ARB9Py_JjM-S"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX0Mz4s-jM-S"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyOHiApujM-S"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmnQOQU3jM-S"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkUzeyCsjM-T"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has:\n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer,\n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "F6XrIeXljM-T"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential, Input, layers\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), activation='relu', padding='same', input_shape=(28,28,1)))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "    ### Flattening\n",
        "    # YOUR C\n",
        "\n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "\n",
        "\n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    ### Model compilation\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2v_vt3LjM-T"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì\n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "sEO7-WBjjM-T",
        "outputId": "10a7b9a1-38fd-4512-bd55-ddaee9b96e81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m8\u001b[0m)      ‚îÇ           \u001b[38;5;34m136\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)      ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m16\u001b[0m)     ‚îÇ         \u001b[38;5;34m1,168\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)       ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ         \u001b[38;5;34m9,232\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             ‚îÇ           \u001b[38;5;34m170\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,232</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,706\u001b[0m (41.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,706</span> (41.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,706\u001b[0m (41.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,706</span> (41.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "cnn_model = initialize_model()\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4o44Y-ejM-T"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kPNqlFrjM-T"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì\n",
        "\n",
        "Initialize your model and fit it on the train data.\n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**.\n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX63Pv06jM-U",
        "outputId": "dc189ee0-1ee6-4674-beaf-16b40846bbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 - 28s - 18ms/step - accuracy: 0.9111 - loss: 0.2844 - val_accuracy: 0.9698 - val_loss: 0.1031\n",
            "Epoch 2/5\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9695 - loss: 0.0983 - val_accuracy: 0.9781 - val_loss: 0.0737\n",
            "Epoch 3/5\n",
            "1500/1500 - 26s - 17ms/step - accuracy: 0.9769 - loss: 0.0740 - val_accuracy: 0.9751 - val_loss: 0.0877\n",
            "Epoch 4/5\n",
            "1500/1500 - 25s - 17ms/step - accuracy: 0.9813 - loss: 0.0603 - val_accuracy: 0.9843 - val_loss: 0.0556\n",
            "Epoch 5/5\n",
            "1500/1500 - 41s - 27ms/step - accuracy: 0.9843 - loss: 0.0512 - val_accuracy: 0.9841 - val_loss: 0.0532\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Initialize the model\n",
        "cnn_model = initialize_model()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',   # stop when validation loss stops improving\n",
        "    patience=2,           # wait 2 epochs before stopping\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "history = cnn_model.fit(\n",
        "    x_train, y_train_cat,         # training data and one-hot labels\n",
        "    epochs=5,                     # max epochs\n",
        "    batch_size=32,                # typical batch size\n",
        "    validation_split=0.2,         # 20% of training data for validation\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3DrF1qQjM-U"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "9KwF50hgjM-U"
      },
      "source": [
        "1875"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jD0pDCRjM-U"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32:\n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss`\n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGtZuIbjM-a"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKF7Q8e5jM-a"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì\n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS2Mmvl0jM-a",
        "outputId": "92531c56-abf7-48b4-9a7a-e725d7b21a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9855\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = cnn_model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoAtDcMfjM-a"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-KrXWwbjM-a"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}